{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying files from local to HDFS\n",
    "\n",
    "We can copy files from local file system to HDFS either by using `copyFromLocal` or `put` command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `hdfs dfs -copyFromLocal` or `hdfs dfs -put` â€“ to copy files or directories from local filesystem into HDFS. We can also use `hadoop fs` in place of `hdfs dfs`.\n",
    "* However, we will not be able to update or fix data in files when they are in HDFS. If we have to fix any data, we have to move file to local file system, fix data and then copy back to HDFS.\n",
    "* Files will be divided into blocks and will be stored on Datanodes in distributed fashion based on block size and replication factor. We will get into the details later.\n",
    "\n",
    "![test](https://s3.amazonaws.com/kaizen.spark.com/hadoop-overview/04HDFSAnatomyOfFileWrite.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:08 /user/spark/.sparkStaging\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/`whoami`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -mkdir /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:08 /user/spark/.sparkStaging\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/`whoami`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-put [-f] [-p] [-l] [-d] <localsrc> ... <dst> :\n",
      "  Copy files from the local file system into fs. Copying fails if the file already\n",
      "  exists, unless the -f flag is given.\n",
      "  Flags:\n",
      "                                                                       \n",
      "  -p  Preserves access and modification times, ownership and the mode. \n",
      "  -f  Overwrites the destination if it already exists.                 \n",
      "  -l  Allow DataNode to lazily persist the file to disk. Forces        \n",
      "         replication factor of 1. This flag will result in reduced\n",
      "         durability. Use with care.\n",
      "                                                        \n",
      "  -d  Skip creation of temporary file(<dst>._COPYING_). \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -help put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst> :\n",
      "  Copy files from the local file system into fs. Copying fails if the file already\n",
      "  exists, unless the -f flag is given.\n",
      "  Flags:\n",
      "                                                                                 \n",
      "  -p                 Preserves access and modification times, ownership and the  \n",
      "                     mode.                                                       \n",
      "  -f                 Overwrites the destination if it already exists.            \n",
      "  -t <thread count>  Number of threads to be used, default is 1.                 \n",
      "  -l                 Allow DataNode to lazily persist the file to disk. Forces   \n",
      "                     replication factor of 1. This flag will result in reduced   \n",
      "                     durability. Use with care.                                  \n",
      "  -d                 Skip creation of temporary file(<dst>._COPYING_).           \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -help copyFromLocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "This will copy the entire folder to `/user/${USER}/retail_db` and you will see `/user/${USER}/retail_db/retail_db`. You can use the next command to get files as expected.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20128\n",
      "drwxr-xr-x 3 spark spark       96 May 28 12:57 customers\n",
      "drwxr-xr-x 3 spark spark       96 May 28 12:57 products\n",
      "-rw-r--r-- 1 spark spark     1748 May 28 12:57 create_db_tables_pg.sql\n",
      "drwxr-xr-x 3 spark spark       96 May 28 12:57 departments\n",
      "drwxr-xr-x 3 spark spark       96 May 28 12:57 order_items\n",
      "-rw-r--r-- 1 spark spark 10303297 May 28 12:57 create_db.sql\n",
      "drwxr-xr-x 3 spark spark       96 May 28 12:57 orders\n",
      "drwxr-xr-x 3 spark spark       96 May 28 12:57 categories\n",
      "-rw-r--r-- 1 spark spark 10297372 May 28 12:57 load_db_tables_pg.sql\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "ls -ltr /data/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -put /data/retail_db /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/retail_db\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/retail_db/categories\n",
      "-rw-r--r--   1 spark supergroup   10303297 2022-05-29 17:23 /user/spark/retail_db/retail_db/create_db.sql\n",
      "-rw-r--r--   1 spark supergroup       1748 2022-05-29 17:23 /user/spark/retail_db/retail_db/create_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/retail_db/customers\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/retail_db/departments\n",
      "-rw-r--r--   1 spark supergroup   10297372 2022-05-29 17:23 /user/spark/retail_db/retail_db/load_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/retail_db/order_items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/retail_db/orders\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/retail_db/products\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/`whoami`/retail_db/retail_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Let's drop this folder and make sure files are copied as expected. As the folder is pre-created, we can use patterns to copy the sub folders.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ... :\n",
      "  Delete all files that match the specified file pattern. Equivalent to the Unix\n",
      "  command \"rm <src>\"\n",
      "                                                                                 \n",
      "  -f          If the file does not exist, do not display a diagnostic message or \n",
      "              modify the exit status to reflect an error.                        \n",
      "  -[rR]       Recursively deletes directories.                                   \n",
      "  -skipTrash  option bypasses trash, if enabled, and immediately deletes <src>.  \n",
      "  -safely     option requires safety confirmation, if enabled, requires          \n",
      "              confirmation before deleting large directory with more than        \n",
      "              <hadoop.shell.delete.limit.num.files> files. Delay is expected when\n",
      "              walking over large directory recursively to count the number of    \n",
      "              files to be deleted before the confirmation.                       \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -help rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/spark/retail_db/retail_db\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -rm -R -skipTrash /user/`whoami`/retail_db/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/`whoami`/retail_db/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -put /data/retail_db/order* /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/order_items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/orders\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/`whoami`/retail_db/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -put -f /data/retail_db/* /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/categories\n",
      "-rw-r--r--   1 spark supergroup   10303297 2022-05-29 17:23 /user/spark/retail_db/create_db.sql\n",
      "-rw-r--r--   1 spark supergroup       1748 2022-05-29 17:23 /user/spark/retail_db/create_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/customers\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/departments\n",
      "-rw-r--r--   1 spark supergroup   10297372 2022-05-29 17:23 /user/spark/retail_db/load_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/order_items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/orders\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/products\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/`whoami`/retail_db/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/categories\n",
      "-rw-r--r--   1 spark supergroup       1029 2022-05-29 17:23 /user/spark/retail_db/categories/part-00000\n",
      "-rw-r--r--   1 spark supergroup   10303297 2022-05-29 17:23 /user/spark/retail_db/create_db.sql\n",
      "-rw-r--r--   1 spark supergroup       1748 2022-05-29 17:23 /user/spark/retail_db/create_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/customers\n",
      "-rw-r--r--   1 spark supergroup     953719 2022-05-29 17:23 /user/spark/retail_db/customers/part-00000\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/departments\n",
      "-rw-r--r--   1 spark supergroup         60 2022-05-29 17:23 /user/spark/retail_db/departments/part-00000\n",
      "-rw-r--r--   1 spark supergroup   10297372 2022-05-29 17:23 /user/spark/retail_db/load_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/order_items\n",
      "-rw-r--r--   1 spark supergroup    5408880 2022-05-29 17:23 /user/spark/retail_db/order_items/part-00000\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/orders\n",
      "-rw-r--r--   1 spark supergroup    2999944 2022-05-29 17:23 /user/spark/retail_db/orders/part-00000\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/products\n",
      "-rw-r--r--   1 spark supergroup     174155 2022-05-29 17:23 /user/spark/retail_db/products/part-00000\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls -R /user/`whoami`/retail_db/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Alternatively you can use `copyFromLocal` as well.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/spark/retail_db\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -rm -R -skipTrash /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -mkdir /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/spark/retail_db/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -copyFromLocal /data/retail_db/* /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/categories\n",
      "-rw-r--r--   1 spark supergroup   10303297 2022-05-29 17:23 /user/spark/retail_db/create_db.sql\n",
      "-rw-r--r--   1 spark supergroup       1748 2022-05-29 17:23 /user/spark/retail_db/create_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/customers\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/departments\n",
      "-rw-r--r--   1 spark supergroup   10297372 2022-05-29 17:23 /user/spark/retail_db/load_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/order_items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/orders\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/products\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "We can also use this alternative approach to directly copy the folder `/data/retail_db` to `/user/${USER}/retail_db`. Let us first delete `/user/${USER}/retail_db` using `skipTrash`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/spark/retail_db\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -rm -R -skipTrash /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "We can specify the target location as `/user/${USER}`. It will create the retail_db folder and its contents.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -put /data/retail_db /user/`whoami`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/categories\n",
      "-rw-r--r--   1 spark supergroup   10303297 2022-05-29 17:23 /user/spark/retail_db/create_db.sql\n",
      "-rw-r--r--   1 spark supergroup       1748 2022-05-29 17:23 /user/spark/retail_db/create_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/customers\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/departments\n",
      "-rw-r--r--   1 spark supergroup   10297372 2022-05-29 17:23 /user/spark/retail_db/load_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/order_items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/orders\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:23 /user/spark/retail_db/products\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we try to run `hdfs dfs -put /data/retail_db /user/${USER}` again it will fail as the target folder already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put: `/user/spark/retail_db/categories/part-00000': File exists\n",
      "put: `/user/spark/retail_db/create_db.sql': File exists\n",
      "put: `/user/spark/retail_db/create_db_tables_pg.sql': File exists\n",
      "put: `/user/spark/retail_db/customers/part-00000': File exists\n",
      "put: `/user/spark/retail_db/departments/part-00000': File exists\n",
      "put: `/user/spark/retail_db/load_db_tables_pg.sql': File exists\n",
      "put: `/user/spark/retail_db/order_items/part-00000': File exists\n",
      "put: `/user/spark/retail_db/orders/part-00000': File exists\n",
      "put: `/user/spark/retail_db/products/part-00000': File exists\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\nhdfs dfs -put /data/retail_db /user/`whoami`\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e096375d17bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nhdfs dfs -put /data/retail_db /user/`whoami`\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2369\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2371\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2372\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\nhdfs dfs -put /data/retail_db /user/`whoami`\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -put /data/retail_db /user/`whoami`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can use `-f` as part of `put` or `copyFromLocal` to replace existing folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -put -f /data/retail_db /user/`whoami`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/categories\n",
      "-rw-r--r--   1 spark supergroup   10303297 2022-05-29 17:24 /user/spark/retail_db/create_db.sql\n",
      "-rw-r--r--   1 spark supergroup       1748 2022-05-29 17:24 /user/spark/retail_db/create_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/customers\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/departments\n",
      "-rw-r--r--   1 spark supergroup   10297372 2022-05-29 17:24 /user/spark/retail_db/load_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/order_items\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/orders\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/products\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/categories\n",
      "-rw-r--r--   1 spark supergroup       1029 2022-05-29 17:24 /user/spark/retail_db/categories/part-00000\n",
      "-rw-r--r--   1 spark supergroup   10303297 2022-05-29 17:24 /user/spark/retail_db/create_db.sql\n",
      "-rw-r--r--   1 spark supergroup       1748 2022-05-29 17:24 /user/spark/retail_db/create_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/customers\n",
      "-rw-r--r--   1 spark supergroup     953719 2022-05-29 17:24 /user/spark/retail_db/customers/part-00000\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/departments\n",
      "-rw-r--r--   1 spark supergroup         60 2022-05-29 17:24 /user/spark/retail_db/departments/part-00000\n",
      "-rw-r--r--   1 spark supergroup   10297372 2022-05-29 17:24 /user/spark/retail_db/load_db_tables_pg.sql\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/order_items\n",
      "-rw-r--r--   1 spark supergroup    5408880 2022-05-29 17:24 /user/spark/retail_db/order_items/part-00000\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/orders\n",
      "-rw-r--r--   1 spark supergroup    2999944 2022-05-29 17:24 /user/spark/retail_db/orders/part-00000\n",
      "drwxr-xr-x   - spark supergroup          0 2022-05-29 17:24 /user/spark/retail_db/products\n",
      "-rw-r--r--   1 spark supergroup     174155 2022-05-29 17:24 /user/spark/retail_db/products/part-00000\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls -R /user/`whoami`/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets for Joins\n",
    "Let us prepare datasets to join. We will be using Airtraffic data as well as retail data while going through the tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make sure airport-codes is in HDFS.\n",
    "* We will also use airtraffic data for the month of January 2008. We have used that data set in the past as well.\n",
    "* We will be using retail data using JSON format. Make sure you also have the retail data using JSON format in appropriate location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.spark.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Joining Data Sets'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-03-02 19:48 /public/airtraffic_all/airport-codes\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-03-02 19:42 /public/airtraffic_all/airtraffic\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-03-02 19:48 /public/airtraffic_all/airtraffic-part\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /public/airtraffic_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   3 hdfs supergroup      11411 2021-03-02 19:48 /public/airtraffic_all/airport-codes/airport-codes-na.txt\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /public/airtraffic_all/airport-codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodesPath = \"/public/airtraffic_all/airport-codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes = spark. \\\n",
    "    read. \\\n",
    "    option(\"sep\", \"\\t\"). \\\n",
    "    option(\"header\", True). \\\n",
    "    option(\"inferSchema\", True). \\\n",
    "    csv(airportCodesPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- IATA: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airportCodes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------+----+\n",
      "|       City|State|Country|IATA|\n",
      "+-----------+-----+-------+----+\n",
      "| Abbotsford|   BC| Canada| YXX|\n",
      "|   Aberdeen|   SD|    USA| ABR|\n",
      "|    Abilene|   TX|    USA| ABI|\n",
      "|      Akron|   OH|    USA| CAK|\n",
      "|    Alamosa|   CO|    USA| ALS|\n",
      "|     Albany|   GA|    USA| ABY|\n",
      "|     Albany|   NY|    USA| ALB|\n",
      "|Albuquerque|   NM|    USA| ABQ|\n",
      "| Alexandria|   LA|    USA| AEX|\n",
      "|  Allentown|   PA|    USA| ABE|\n",
      "|   Alliance|   NE|    USA| AIA|\n",
      "|     Alpena|   MI|    USA| APN|\n",
      "|    Altoona|   PA|    USA| AOO|\n",
      "|   Amarillo|   TX|    USA| AMA|\n",
      "|Anahim Lake|   BC| Canada| YAA|\n",
      "|  Anchorage|   AK|    USA| ANC|\n",
      "|   Appleton|   WI|    USA| ATW|\n",
      "|     Arviat|  NWT| Canada| YEK|\n",
      "|  Asheville|   NC|    USA| AVL|\n",
      "|      Aspen|   CO|    USA| ASE|\n",
      "+-----------+-----+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airportCodes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airportCodes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   3 hdfs supergroup   14654075 2021-03-02 19:47 /public/airtraffic_all/airtraffic-part/flightmonth=200801/part-00252-5cde1303-4ebf-4a12-8fad-f5d9f9c9124a.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /public/airtraffic_all/airtraffic-part/flightmonth=200801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/public/retail_db_json\n",
      "/public/retail_db_json/categories\n",
      "/public/retail_db_json/categories/_SUCCESS\n",
      "/public/retail_db_json/categories/part-r-00000-ce1d8208-178d-48d3-bfb2-1a97d9c05094\n",
      "/public/retail_db_json/customers\n",
      "/public/retail_db_json/customers/_SUCCESS\n",
      "/public/retail_db_json/customers/part-r-00000-70554560-527b-44f6-9e80-4e2031af5994\n",
      "/public/retail_db_json/departments\n",
      "/public/retail_db_json/departments/_SUCCESS\n",
      "/public/retail_db_json/departments/part-r-00000-3db7cfae-3ad2-4fc7-88ff-afe0ec709f49\n",
      "/public/retail_db_json/order_details\n",
      "/public/retail_db_json/order_details/order_details.json\n",
      "/public/retail_db_json/order_items\n",
      "/public/retail_db_json/order_items/_SUCCESS\n",
      "/public/retail_db_json/order_items/part-r-00000-6b83977e-3f20-404b-9b5f-29376ab1419e\n",
      "/public/retail_db_json/orders\n",
      "/public/retail_db_json/orders/_SUCCESS\n",
      "/public/retail_db_json/orders/part-r-00000-990f5773-9005-49ba-b670-631286032674\n",
      "/public/retail_db_json/products\n",
      "/public/retail_db_json/products/_SUCCESS\n",
      "/public/retail_db_json/products/part-r-00000-158b7037-4a23-47e6-8cb3-8cbf878beff7\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -find /public/retail_db_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = spark.read.json('/public/retail_db_json/orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_customer_id: long (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------+---------------+\n",
      "|order_customer_id|          order_date|order_id|   order_status|\n",
      "+-----------------+--------------------+--------+---------------+\n",
      "|            11599|2013-07-25 00:00:...|       1|         CLOSED|\n",
      "|              256|2013-07-25 00:00:...|       2|PENDING_PAYMENT|\n",
      "|            12111|2013-07-25 00:00:...|       3|       COMPLETE|\n",
      "|             8827|2013-07-25 00:00:...|       4|         CLOSED|\n",
      "|            11318|2013-07-25 00:00:...|       5|       COMPLETE|\n",
      "|             7130|2013-07-25 00:00:...|       6|       COMPLETE|\n",
      "|             4530|2013-07-25 00:00:...|       7|       COMPLETE|\n",
      "|             2911|2013-07-25 00:00:...|       8|     PROCESSING|\n",
      "|             5657|2013-07-25 00:00:...|       9|PENDING_PAYMENT|\n",
      "|             5648|2013-07-25 00:00:...|      10|PENDING_PAYMENT|\n",
      "|              918|2013-07-25 00:00:...|      11| PAYMENT_REVIEW|\n",
      "|             1837|2013-07-25 00:00:...|      12|         CLOSED|\n",
      "|             9149|2013-07-25 00:00:...|      13|PENDING_PAYMENT|\n",
      "|             9842|2013-07-25 00:00:...|      14|     PROCESSING|\n",
      "|             2568|2013-07-25 00:00:...|      15|       COMPLETE|\n",
      "|             7276|2013-07-25 00:00:...|      16|PENDING_PAYMENT|\n",
      "|             2667|2013-07-25 00:00:...|      17|       COMPLETE|\n",
      "|             1205|2013-07-25 00:00:...|      18|         CLOSED|\n",
      "|             9488|2013-07-25 00:00:...|      19|PENDING_PAYMENT|\n",
      "|             9198|2013-07-25 00:00:...|      20|     PROCESSING|\n",
      "+-----------------+--------------------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68883"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Tables\n",
    "\n",
    "Let us prepare the tables to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make sure database is created.\n",
    "* Create **orders** table.\n",
    "* Load data from local path **/data/retail_db/orders** into newly created **orders** table.\n",
    "* Preview data and get count from **orders**\n",
    "* Create **order_items** table.\n",
    "* Load data from local path **/data/retail_db/order_items** into newly created **orders** table.\n",
    "* Preview data and get count from **order_items**\n",
    "\n",
    "As tables and data are ready let us get into how to write queries against tables to perform basic transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.spark.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = spark\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "spark"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val username = System.getProperty(\"user.name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = spark\n",
       "spark = org.apache.spark.sql.SparkSession@4c4dbcd1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@4c4dbcd1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val username = System.getProperty(\"user.name\")\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    config(\"spark.sql.warehouse.dir\", s\"/user/${username}/warehouse\").\n",
    "    enableHiveSupport.\n",
    "    appName(s\"${username} | Spark SQL - Basic Transformations\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Magic sql failed to execute with error: \n",
       "org.apache.hadoop.hive.metastore.api.NoSuchObjectException: spark_retail;"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "DROP DATABASE spark_retail CASCADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE DATABASE IF NOT EXISTS spark_retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "USE spark_retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+---------+-----------+\n",
       "|database|tableName|isTemporary|\n",
       "+--------+---------+-----------+\n",
       "+--------+---------+-----------+\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SHOW tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Magic sql failed to execute with error: \n",
       "Table or view not found: orders;"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE orders (\n",
    "    order_id INT,\n",
    "    order_date STRING,\n",
    "    order_customer_id INT,\n",
    "    order_status STRING\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = spark\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "val username = System.getProperty(\"user.name\")\n",
    "s\"hdfs dfs -ls /user/spark/warehouse/${username}_retail.db/orders\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "LOAD DATA LOCAL INPATH '/data/retail_db/orders' INTO TABLE orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rwxr-xr-x   1 spark supergroup    2999944 2022-02-02 04:07 /user/spark/warehouse/spark_retail.db/orders/part-00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "username = spark\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "val username = System.getProperty(\"user.name\")\n",
    "s\"hdfs dfs -ls /user/spark/warehouse/${username}_retail.db/orders\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|       8|2013-07-25 00:00:...|             2911|     PRO...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "+--------+--------------------+-----------------+---------------+\n",
       "|order_id|          order_date|order_customer_id|   order_status|\n",
       "+--------+--------------------+-----------------+---------------+\n",
       "|       1|2013-07-25 00:00:...|            11599|         CLOSED|\n",
       "|       2|2013-07-25 00:00:...|              256|PENDING_PAYMENT|\n",
       "|       3|2013-07-25 00:00:...|            12111|       COMPLETE|\n",
       "|       4|2013-07-25 00:00:...|             8827|         CLOSED|\n",
       "|       5|2013-07-25 00:00:...|            11318|       COMPLETE|\n",
       "|       6|2013-07-25 00:00:...|             7130|       COMPLETE|\n",
       "|       7|2013-07-25 00:00:...|             4530|       COMPLETE|\n",
       "|       8|2013-07-25 00:00:...|             2911|     PROCESSING|\n",
       "|       9|2013-07-25 00:00:...|             5657|PENDING_PAYMENT|\n",
       "|      10|2013-07-25 00:00:...|             5648|PENDING_PAYMENT|\n",
       "+--------+--------------------+-----------------+---------------+\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM orders LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "|   68883|\n",
       "+--------+\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT count(1) FROM orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Magic sql failed to execute with error: \n",
       "Table or view not found: order_items;"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE order_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "CREATE TABLE order_items (\n",
    "    order_item_id INT,\n",
    "    order_item_order_id INT,\n",
    "    order_item_product_id INT,\n",
    "    order_item_quantity INT,\n",
    "    order_item_subtotal FLOAT,\n",
    "    order_item_product_price FLOAT\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = spark\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "val username = System.getProperty(\"user.name\")\n",
    "s\"hdfs dfs -ls /user/spark/warehouse/${username}_retail.db/order_items\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "LOAD DATA LOCAL INPATH '/data/retail_db/order_items' INTO TABLE order_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rwxr-xr-x   1 spark supergroup    5408880 2022-02-02 03:20 /user/spark/warehouse/spark_retail.db/order_items/part-00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "username = spark\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "val username = System.getProperty(\"user.name\")\n",
    "s\"hdfs dfs -ls /user/spark/warehouse/${username}_retail.db/order_items\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|            3|                  2|                  502|                  5|              250.0|     ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
       "|order_item_id|order_item_order_id|order_item_product_id|order_item_quantity|order_item_subtotal|order_item_product_price|\n",
       "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
       "|            1|                  1|                  957|                  1|             299.98|                  299.98|\n",
       "|            2|                  2|                 1073|                  1|             199.99|                  199.99|\n",
       "|            3|                  2|                  502|                  5|              250.0|                    50.0|\n",
       "|            4|                  2|                  403|                  1|             129.99|                  129.99|\n",
       "|            5|                  4|                  897|                  2|              49.98|                   24.99|\n",
       "|            6|                  4|                  365|                  5|             299.95|                   59.99|\n",
       "|            7|                  4|                  502|                  3|              150.0|                    50.0|\n",
       "|            8|                  4|                 1014|                  4|             199.92|                   49.98|\n",
       "|            9|                  5|                  957|                  1|             299.98|                  299.98|\n",
       "|           10|                  5|                  365|                  5|             299.95|                   59.99|\n",
       "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
       "\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM order_items LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "|  172198|\n",
       "+--------+\n",
       "\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT count(1) FROM order_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using Spark SQL with Python or Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP DATABASE spark_retail CASCADE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS spark_retail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE spark_retail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[database: string, tableName: string ... 1 more field]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SHOW tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": "Table or view not found: orders;",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: Table or view not found: orders;",
      "  at org.apache.spark.sql.execution.command.DropTableCommand.run(ddl.scala:220)",
      "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)",
      "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)",
      "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:79)",
      "  at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:194)",
      "  at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:194)",
      "  at org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)",
      "  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)",
      "  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)",
      "  at org.apache.spark.sql.Dataset.<init>(Dataset.scala:194)",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:79)",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:643)",
      "  ... 50 elided"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE orders (\n",
    "    order_id INT,\n",
    "    order_date STRING,\n",
    "    order_customer_id INT,\n",
    "    order_status STRING\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = spark\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "val username = System.getProperty(\"user.name\")\n",
    "s\"hdfs dfs -ls /user/spark/warehouse/${username}_retail.db/orders\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"LOAD DATA LOCAL INPATH '/data/retail_db/orders' INTO TABLE orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rwxr-xr-x   1 spark supergroup    2999944 2022-02-02 03:20 /user/spark/warehouse/spark_retail.db/orders/part-00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "username = spark\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "val username = System.getProperty(\"user.name\")\n",
    "s\"hdfs dfs -ls /user/spark/warehouse/${username}_retail.db/orders\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------+---------------+\n",
      "|order_id|          order_date|order_customer_id|   order_status|\n",
      "+--------+--------------------+-----------------+---------------+\n",
      "|   34565|2014-02-23 00:00:...|             8702|       COMPLETE|\n",
      "|   34566|2014-02-23 00:00:...|             3066|PENDING_PAYMENT|\n",
      "|   34567|2014-02-23 00:00:...|             7314|SUSPECTED_FRAUD|\n",
      "|   34568|2014-02-23 00:00:...|             1271|       COMPLETE|\n",
      "|   34569|2014-02-23 00:00:...|            11083|       COMPLETE|\n",
      "|   34570|2014-02-23 00:00:...|             3159|         CLOSED|\n",
      "|   34571|2014-02-23 00:00:...|             4551|         CLOSED|\n",
      "|   34572|2014-02-23 00:00:...|             8135|        PENDING|\n",
      "|   34573|2014-02-23 00:00:...|             7497|PENDING_PAYMENT|\n",
      "|   34574|2014-02-23 00:00:...|             1868|        ON_HOLD|\n",
      "+--------+--------------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM orders LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   68883|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(1) FROM orders\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": "Table or view not found: order_items;",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: Table or view not found: order_items;",
      "  at org.apache.spark.sql.execution.command.DropTableCommand.run(ddl.scala:220)",
      "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)",
      "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)",
      "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:79)",
      "  at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:194)",
      "  at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:194)",
      "  at org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)",
      "  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)",
      "  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)",
      "  at org.apache.spark.sql.Dataset.<init>(Dataset.scala:194)",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:79)",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:643)",
      "  ... 54 elided"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE order_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE order_items (\n",
    "    order_item_id INT,\n",
    "    order_item_order_id INT,\n",
    "    order_item_product_id INT,\n",
    "    order_item_quantity INT,\n",
    "    order_item_subtotal FLOAT,\n",
    "    order_item_product_price FLOAT\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = spark\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "val username = System.getProperty(\"user.name\")\n",
    "s\"hdfs dfs -ls /user/spark/warehouse/${username}_retail.db/order_items\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"LOAD DATA LOCAL INPATH '/data/retail_db/order_items' INTO TABLE order_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rwxr-xr-x   1 spark supergroup    5408880 2022-02-02 03:21 /user/spark/warehouse/spark_retail.db/order_items/part-00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "username = spark\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "val username = System.getProperty(\"user.name\")\n",
    "s\"hdfs dfs -ls /user/spark/warehouse/${username}_retail.db/order_items\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
      "|order_item_id|order_item_order_id|order_item_product_id|order_item_quantity|order_item_subtotal|order_item_product_price|\n",
      "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
      "|            1|                  1|                  957|                  1|             299.98|                  299.98|\n",
      "|            2|                  2|                 1073|                  1|             199.99|                  199.99|\n",
      "|            3|                  2|                  502|                  5|              250.0|                    50.0|\n",
      "|            4|                  2|                  403|                  1|             129.99|                  129.99|\n",
      "|            5|                  4|                  897|                  2|              49.98|                   24.99|\n",
      "|            6|                  4|                  365|                  5|             299.95|                   59.99|\n",
      "|            7|                  4|                  502|                  3|              150.0|                    50.0|\n",
      "|            8|                  4|                 1014|                  4|             199.92|                   49.98|\n",
      "|            9|                  5|                  957|                  1|             299.98|                  299.98|\n",
      "|           10|                  5|                  365|                  5|             299.95|                   59.99|\n",
      "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM order_items LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  172198|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(1) FROM order_items\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

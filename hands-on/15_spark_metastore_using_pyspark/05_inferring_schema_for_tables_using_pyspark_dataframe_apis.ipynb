{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring Schema for Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we want to create a table using `spark.catalog.createTable` or using `spark.catalog.createExternalTable`, we need to specify Schema.\n",
    "\n",
    "* Schema can be inferred from the Dataframe and then can be passed using `StructType` object while creating the table.\n",
    "* `StructType` takes list of objects of type `StructField`.\n",
    "* `StructField` is built using column name and data type. All the data types are available under `pyspark.sql.types`.\n",
    "* We need to pass table name and schema for `spark.catalog.createTable`.\n",
    "* We have to pass path along with name and schema for `spark.catalog.createExternalTable`.\n",
    "* We can use source to define file format along with applicable options. For example, if we want to create a table for CSV, then source will be csv and we can pass applicable options for CSV such as sep, header etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.spark.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Spark Metastore'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.shuffle.partitions', '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "* Create database by name **{username}_airtraffic** and create external table for **airport-codes.txt**.\n",
    "  * Data have header\n",
    "  * Fields in each record are delimited by a tab character.\n",
    "  * We can pass options such as sep, header, inferSchema etc to define the schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateExternalTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtableName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Creates a table based on the dataset in a data source.\n",
       "\n",
       "It returns the DataFrame associated with the external table.\n",
       "\n",
       "The data source is specified by the ``source`` and a set of ``options``.\n",
       "If ``source`` is not specified, the default data source configured by\n",
       "``spark.sql.sources.default`` will be used.\n",
       "\n",
       "Optionally, a schema can be provided as the schema of the returned :class:`DataFrame` and\n",
       "created external table.\n",
       "\n",
       ":return: :class:`DataFrame`\n",
       "\n",
       ".. versionadded:: 2.0\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.catalog.createExternalTable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "username = getpass.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {username}_airtraffic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(f\"{username}_airtraffic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark_airtraffic'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To create external table, we need to have write permissions over the path which we want to use.\n",
    "* As we have only read permissions on **/public/airtraffic_all/airport-codes** we cannot use that path while creating external table.\n",
    "* Let us copy the data to **/user/`whoami`/airtraffic_all/airport-codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   3 spark spark      11411 2021-03-12 10:57 /user/spark/airtraffic_all/airport-codes/airport-codes-na.txt\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -mkdir -p /user/`whoami`/airtraffic_all\n",
    "hdfs dfs -cp -f /public/airtraffic_all/airport-codes /user/`whoami`/airtraffic_all\n",
    "hdfs dfs -ls /user/`whoami`/airtraffic_all/airport-codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yuma\tAZ\tUSA\tYUM\tCanada\tYZFLa\tYWK"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -tail /user/`whoami`/airtraffic_all/airport-codes/airport-codes-na.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "airport_codes_path = f'/user/{username}/airtraffic_all/airport-codes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('DROP TABLE IF EXISTS airport_codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>City</th><th>State</th><th>Country</th><th>IATA</th></tr>\n",
       "<tr><td>Abbotsford</td><td>BC</td><td>Canada</td><td>YXX</td></tr>\n",
       "<tr><td>Aberdeen</td><td>SD</td><td>USA</td><td>ABR</td></tr>\n",
       "<tr><td>Abilene</td><td>TX</td><td>USA</td><td>ABI</td></tr>\n",
       "<tr><td>Akron</td><td>OH</td><td>USA</td><td>CAK</td></tr>\n",
       "<tr><td>Alamosa</td><td>CO</td><td>USA</td><td>ALS</td></tr>\n",
       "<tr><td>Albany</td><td>GA</td><td>USA</td><td>ABY</td></tr>\n",
       "<tr><td>Albany</td><td>NY</td><td>USA</td><td>ALB</td></tr>\n",
       "<tr><td>Albuquerque</td><td>NM</td><td>USA</td><td>ABQ</td></tr>\n",
       "<tr><td>Alexandria</td><td>LA</td><td>USA</td><td>AEX</td></tr>\n",
       "<tr><td>Allentown</td><td>PA</td><td>USA</td><td>ABE</td></tr>\n",
       "<tr><td>Alliance</td><td>NE</td><td>USA</td><td>AIA</td></tr>\n",
       "<tr><td>Alpena</td><td>MI</td><td>USA</td><td>APN</td></tr>\n",
       "<tr><td>Altoona</td><td>PA</td><td>USA</td><td>AOO</td></tr>\n",
       "<tr><td>Amarillo</td><td>TX</td><td>USA</td><td>AMA</td></tr>\n",
       "<tr><td>Anahim Lake</td><td>BC</td><td>Canada</td><td>YAA</td></tr>\n",
       "<tr><td>Anchorage</td><td>AK</td><td>USA</td><td>ANC</td></tr>\n",
       "<tr><td>Appleton</td><td>WI</td><td>USA</td><td>ATW</td></tr>\n",
       "<tr><td>Arviat</td><td>NWT</td><td>Canada</td><td>YEK</td></tr>\n",
       "<tr><td>Asheville</td><td>NC</td><td>USA</td><td>AVL</td></tr>\n",
       "<tr><td>Aspen</td><td>CO</td><td>USA</td><td>ASE</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----------+-----+-------+----+\n",
       "|       City|State|Country|IATA|\n",
       "+-----------+-----+-------+----+\n",
       "| Abbotsford|   BC| Canada| YXX|\n",
       "|   Aberdeen|   SD|    USA| ABR|\n",
       "|    Abilene|   TX|    USA| ABI|\n",
       "|      Akron|   OH|    USA| CAK|\n",
       "|    Alamosa|   CO|    USA| ALS|\n",
       "|     Albany|   GA|    USA| ABY|\n",
       "|     Albany|   NY|    USA| ALB|\n",
       "|Albuquerque|   NM|    USA| ABQ|\n",
       "| Alexandria|   LA|    USA| AEX|\n",
       "|  Allentown|   PA|    USA| ABE|\n",
       "|   Alliance|   NE|    USA| AIA|\n",
       "|     Alpena|   MI|    USA| APN|\n",
       "|    Altoona|   PA|    USA| AOO|\n",
       "|   Amarillo|   TX|    USA| AMA|\n",
       "|Anahim Lake|   BC| Canada| YAA|\n",
       "|  Anchorage|   AK|    USA| ANC|\n",
       "|   Appleton|   WI|    USA| ATW|\n",
       "|     Arviat|  NWT| Canada| YEK|\n",
       "|  Asheville|   NC|    USA| AVL|\n",
       "|      Aspen|   CO|    USA| ASE|\n",
       "+-----------+-----+-------+----+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog. \\\n",
    "    createExternalTable(\"airport_codes\",\n",
    "                        path=airport_codes_path,\n",
    "                        source=\"csv\",\n",
    "                        sep=\"\\t\",\n",
    "                        header=\"true\",\n",
    "                        inferSchema=\"true\"\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='airport_codes', database='spark_airtraffic', description=None, tableType='EXTERNAL', isTemporary=False)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------+----+\n",
      "|       City|State|Country|IATA|\n",
      "+-----------+-----+-------+----+\n",
      "| Abbotsford|   BC| Canada| YXX|\n",
      "|   Aberdeen|   SD|    USA| ABR|\n",
      "|    Abilene|   TX|    USA| ABI|\n",
      "|      Akron|   OH|    USA| CAK|\n",
      "|    Alamosa|   CO|    USA| ALS|\n",
      "|     Albany|   GA|    USA| ABY|\n",
      "|     Albany|   NY|    USA| ALB|\n",
      "|Albuquerque|   NM|    USA| ABQ|\n",
      "| Alexandria|   LA|    USA| AEX|\n",
      "|  Allentown|   PA|    USA| ABE|\n",
      "|   Alliance|   NE|    USA| AIA|\n",
      "|     Alpena|   MI|    USA| APN|\n",
      "|    Altoona|   PA|    USA| AOO|\n",
      "|   Amarillo|   TX|    USA| AMA|\n",
      "|Anahim Lake|   BC| Canada| YAA|\n",
      "|  Anchorage|   AK|    USA| ANC|\n",
      "|   Appleton|   WI|    USA| ATW|\n",
      "|     Arviat|  NWT| Canada| YEK|\n",
      "|  Asheville|   NC|    USA| AVL|\n",
      "|      Aspen|   CO|    USA| ASE|\n",
      "+-----------+-----+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"airport_codes\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                              |comment|\n",
      "+----------------------------+-----------------------------------------------------------------------+-------+\n",
      "|City                        |string                                                                 |null   |\n",
      "|State                       |string                                                                 |null   |\n",
      "|Country                     |string                                                                 |null   |\n",
      "|IATA                        |string                                                                 |null   |\n",
      "|                            |                                                                       |       |\n",
      "|# Detailed Table Information|                                                                       |       |\n",
      "|Database                    |spark_airtraffic                                                     |       |\n",
      "|Table                       |airport_codes                                                          |       |\n",
      "|Owner                       |spark                                                              |       |\n",
      "|Created Time                |Fri Mar 12 11:00:09 EST 2021                                           |       |\n",
      "|Last Access                 |Wed Dec 31 19:00:00 EST 1969                                           |       |\n",
      "|Created By                  |Spark 2.4.7                                                            |       |\n",
      "|Type                        |EXTERNAL                                                               |       |\n",
      "|Provider                    |csv                                                                    |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1615564809]                                     |       |\n",
      "|Location                    |hdfs://m01.spark.com:9000/user/spark/airtraffic_all/airport-codes|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                     |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.SequenceFileInputFormat                       |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat              |       |\n",
      "|Storage Properties          |[serialization.format=1, inferSchema=true, sep=\t, header=true]         |       |\n",
      "+----------------------------+-----------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('DESCRIBE FORMATTED airport_codes').show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column(name='City', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='State', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='Country', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='IATA', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listColumns('airport_codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
